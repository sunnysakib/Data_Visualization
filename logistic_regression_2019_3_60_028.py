# -*- coding: utf-8 -*-
"""Logistic Regression_2019-3-60-028.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Iy6FJWkDwu6aZt2mLDq4PWWPol5vPlwS
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv("health care diabetes.csv") #load the dataset

data.head()  #show the rows from the dataset

data.isnull().sum() # check null value

data.info()  #checking if there is any inconsistency in the dataset
#as we see there are no null values in the dataset, so the data can be processed

"""Steps To Be followed When Applying an Algorithm

- Split the dataset into training and testing dataset. The testing dataset is generally smaller than training one as it will help in training the model better.
- Select any algorithm based on the problem (classification or regression) whatever you feel may be good.
- Then pass the training dataset to the algorithm to train it. We use the .fit() method
- Then pass the testing data to the trained algorithm to predict the outcome. We use the .predict() method.
- We then check the accuracy by passing the predicted outcome and the actual output to the model.

"""

from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm
from sklearn.model_selection import train_test_split #to split the dataset for training and testing
from sklearn import metrics #for checking the model accuracy
from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve

X= data.drop('Outcome', axis=1)
y=data['Outcome']

train_X, test_X , train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state=30)# in this our main data is split into train and test
# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%
print(train_X.shape)
print(test_X.shape)

train_X.head()

train_y.head()

# Fitting the model
model = LogisticRegression()
model.fit(train_X,train_y)
prediction=model.predict(test_X)

print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,test_y))

from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(test_y, prediction)
print('confusion matrix of test data : ' )
print(conf_matrix)

# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

#Precision Score = TP / (FP + TP)
#Average is required for multiclass/multilabel targets. If None, the scores for each class are returned.
# Otherwise, this determines the type of averaging performed on the data

precision_score(test_y, prediction, average=None)

# Recall Score = TP / (FN + TP)

recall_score(test_y, prediction, average=None)

# F1 Score = 2* Precision Score * Recall Score/ (Precision Score + Recall Score/)

f1_score(test_y, prediction, average=None)

for col in range(test_X.shape[1]):
    tpr,fpr = [],[]
    for threshold in np.linspace(min(test_X[:,col]),max(test_X[:,col]),10):
        detP = test_X[:,col] < threshold
        tpr.append(sum(detP & test_y_)/sum(y_))# TP/P, aka recall
        fpr.append(sum(detP & (~test_y_))/sum((~test_y_)))# FP/N

    if auc(fpr,tpr) < .5:
        aux = tpr
        tpr = fpr
        fpr = aux
    plt.plot(fpr,tpr,label=data.feature_names[col] + ', auc = '\
                           + str(np.round(auc(fpr,tpr),decimals=3)))
plt.title('ROC curve - Iris features')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

fpr, tpr, thresholds = roc_curve(test_y, prediction)
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')